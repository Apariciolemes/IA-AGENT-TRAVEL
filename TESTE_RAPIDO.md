# üß™ Teste R√°pido do Sistema

## 1Ô∏è‚É£ Antes de Iniciar

### Verificar Pr√©-requisitos

```bash
# Docker instalado?
docker --version

# Docker Compose instalado?
docker compose version

# Docker est√° rodando?
docker info
```

### Configurar LLM API Key

**OBRIGAT√ìRIO**: Edite `.env` e adicione sua chave:

```bash
# OpenAI (recomendado)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo-preview
OPENAI_API_KEY=sk-proj-sua-chave-aqui

# OU Anthropic
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-sua-chave-aqui
```

## 2Ô∏è‚É£ Iniciar Sistema

### Op√ß√£o A: Script Autom√°tico

```bash
./scripts/start.sh
```

### Op√ß√£o B: Manual

```bash
docker compose up --build
```

Aguarde at√© ver:
```
travel_backend     | INFO: Application startup complete
travel_frontend    | ‚úî Vite server built
```

## 3Ô∏è‚É£ Verificar Sa√∫de

```bash
# Health check do backend
curl http://localhost:8000/health

# Deve retornar: {"status": "healthy"}
```

```bash
# Frontend carregou?
curl -I http://localhost:3000

# Deve retornar: HTTP/1.1 200 OK
```

## 4Ô∏è‚É£ Testar Funcionalidades

### A) Testar Chat

```bash
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Oi, me ajude a encontrar um voo"
  }'
```

**Resultado Esperado**:
```json
{
  "message": "Ol√°! Claro, vou ajudar voc√™ a encontrar o melhor voo...",
  "conversation_id": "uuid-aqui",
  "needs_clarification": true,
  "missing_fields": ["origin", "destination", "date"]
}
```

### B) Buscar Voos

```bash
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{
    "origin": "GRU",
    "destination": "REC",
    "out_date": "2025-12-15",
    "pax": {"adults": 1},
    "cabin": "ECONOMY",
    "bag_included": true
  }'
```

**Resultado Esperado**: JSON com ~5 ofertas ranqueadas

```json
{
  "ranked": [
    {
      "id": "duffel_...",
      "type": "cash",
      "price": {"cash": {"amount": 450.00}},
      "segments": [...],
      "duration_minutes": 180,
      "stops": 0,
      "explanation": "MELHOR PRE√áO | voo direto..."
    },
    ...
  ],
  "cached": false
}
```

### C) Chat com Busca Completa

```bash
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quero voar de GRU para REC no dia 15 de dezembro, 1 adulto"
  }'
```

**Resultado Esperado**:
- LLM entende os par√¢metros
- Chama `search_flights` automaticamente
- Retorna ofertas + explica√ß√£o

### D) Teste no Frontend

1. Abra: http://localhost:3000
2. Clique em **"Iniciar Chat"**
3. Digite: `Quero voar de S√£o Paulo para Recife dia 15 de dezembro`
4. Aguarde resposta do agente
5. Veja as ofertas aparecerem

## 5Ô∏è‚É£ Verificar Logs

### Backend

```bash
docker compose logs -f backend
```

**Procure por**:
- `llm_client_initialized` ‚Üí LLM configurado
- `agent_processing` ‚Üí Chat processando
- `tool_search_flights` ‚Üí Busca executada
- `offers_ranked` ‚Üí Ranking completo

### Frontend

```bash
docker compose logs -f frontend
```

### Redis (cache)

```bash
docker compose exec redis redis-cli

# Verificar chaves de cache
KEYS search:*

# Ver conte√∫do de uma chave
GET search:abc123...
```

### PostgreSQL

```bash
docker compose exec postgres psql -U travel_user -d travel_agent

# Ver ofertas armazenadas
SELECT id, source, offer_type, origin, destination, out_date FROM offers LIMIT 5;

# Sair
\q
```

## 6Ô∏è‚É£ Testar API Docs Interativa

1. Acesse: http://localhost:8000/docs
2. Expanda **POST /api/v1/search**
3. Clique em "Try it out"
4. Preencha:
```json
{
  "origin": "GRU",
  "destination": "REC",
  "out_date": "2025-12-15",
  "pax": {"adults": 1},
  "cabin": "ECONOMY"
}
```
5. Clique "Execute"
6. Veja resposta abaixo

## 7Ô∏è‚É£ Checklist de Valida√ß√£o

- [ ] Backend respondeu no health check
- [ ] Frontend carrega p√°gina inicial
- [ ] Chat retorna resposta do LLM
- [ ] Busca direta retorna ofertas
- [ ] Chat com busca completa funciona
- [ ] Ofertas t√™m score e explanation
- [ ] Logs mostram eventos estruturados
- [ ] API Docs interativa funciona

## üêõ Troubleshooting

### Erro: "llm_error: authentication failed"

**Causa**: API key inv√°lida

**Solu√ß√£o**:
1. Verifique `.env` ‚Üí `OPENAI_API_KEY` ou `ANTHROPIC_API_KEY`
2. Teste a key:
```bash
# OpenAI
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer sk-sua-key"

# Anthropic
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: sk-ant-sua-key"
```

### Erro: "Connection refused"

**Causa**: Containers n√£o iniciaram

**Solu√ß√£o**:
```bash
docker compose ps  # Ver status
docker compose logs backend  # Ver erros
docker compose restart  # Reiniciar
```

### Chat n√£o chama `search_flights`

**Causa**: LLM n√£o entendeu ou function calling n√£o configurado

**Solu√ß√£o**:
1. Verifique logs: `docker compose logs backend | grep tool`
2. Teste com mensagem mais expl√≠cita: "Buscar voos GRU para REC dia 15/12"
3. Verifique temperature no `.env` (padr√£o: 0.7)

### Ofertas todas iguais

**Causa**: Mock data (esperado no MVP)

**Solu√ß√£o**: Normal! Provedores retornam dados fict√≠cios. Para dados reais:
- Configure `DUFFEL_API_KEY` no `.env`
- Implemente integra√ß√£o real em `providers/duffel_provider.py`

## 8Ô∏è‚É£ Pr√≥ximos Testes (v1)

Quando tiver APIs reais:

```bash
# Testar Duffel
DUFFEL_API_KEY=test_123 docker compose up

# Testar scraping (v1)
SCRAPING_ENABLED=true docker compose up celery_worker
```

## 9Ô∏è‚É£ Parar Sistema

```bash
# Parar mas manter dados
docker compose down

# Parar e remover volumes (limpa banco)
docker compose down -v
```

## üéØ M√©tricas de Sucesso

‚úÖ **Backend**: Responde em < 500ms (health check)
‚úÖ **Chat**: Responde em < 5s (com LLM)
‚úÖ **Busca**: Retorna em < 3s (com cache) ou < 10s (live)
‚úÖ **Ofertas**: M√≠nimo 2-3 ofertas por busca
‚úÖ **Ranking**: Score entre 0-1, explica√ß√£o presente

---

**Tempo estimado de teste**: 10 minutos
**Dificuldade**: F√°cil üü¢

**D√∫vidas?** Consulte:
- `README.md` ‚Üí Vis√£o geral
- `CLAUDE.md` ‚Üí Refer√™ncia t√©cnica
- `STATUS.md` ‚Üí Status do projeto
